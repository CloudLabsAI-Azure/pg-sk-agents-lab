{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d97f8e6",
   "metadata": {},
   "source": [
    "## LAB360: Build an Agentic App with PostgreSQL, GraphRAG, and Semantic Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e253c9",
   "metadata": {},
   "source": [
    "### Part 3.1: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a7fafd",
   "metadata": {},
   "source": [
    "**Welcome to the LAB360 Agent App Notebook!**\n",
    "\n",
    "In this notebook, you will build a Semantic Kernel Agent that can reason over our database of legal cases you deployed in the previous steps. You will also incorporate external web service data, and use memory to improve its responses over time.\n",
    "\n",
    "Semantic Kernel is an open-source SDK developed by Microsoft that helps developers create advanced AI agents by combining:\n",
    "\n",
    "- LLMs (Large Language Models) like OpenAI's GPT models\n",
    "- Plugins (custom tools and functions the agent can call)\n",
    "- Memory (saving and recalling past conversations or facts)\n",
    "\n",
    "An Agent in Semantic Kernel is a smart assistant that can:\n",
    "\n",
    "- Respond to user prompts\n",
    "- Decide which plugin functions to call\n",
    "- Use external knowledge sources like databases or APIs\n",
    "- Build better, grounded answers by combining model reasoning with real-world data\n",
    "\n",
    "You are about to connect powerful components:\n",
    "\n",
    "- Azure OpenAI (for embeddings and LLM chat completions)\n",
    "- PostgreSQL with Vector and Graph extensions (for fast semantic and graph search)\n",
    "- APIs for real-world data (historical weather evidence)\n",
    "\n",
    "As you progress, each section of code will incrementally build up these capabilities, and by the final step, you’ll have a highly capable legal research assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.2: Setup the Agent App Python imports\n",
    "\n",
    "> **Note:** In your lab environment, we already have the PIP packages pre-deployed that are needed by the import statements in the following code block, so you do not need to install these.  But just for reference and for future usage of this code, here are the packages used:\n",
    "> - PostgreSQL connectivity (`psycopg2`, `psycopg-binary`, `psycopg-pool`)\n",
    "> - Modeling and validation (`pydantic`)\n",
    "> - OpenAI and Semantic Kernel integration (`openai`, `semantic-kernel`)\n",
    "> - Notebook compatibility (`nest_asyncio`, `ipykernel`)\n",
    "\n",
    "##### 🧠 *Technical Notes*\n",
    "\n",
    "This set of imports prepares the technical foundation for building an AI-powered agent that interacts with a PostgreSQL database and OpenAI services. `nest_asyncio` is used to allow nested event loops, which is important when running asynchronous code inside a Jupyter notebook. Core Python modules like `os`, `asyncio`, `uuid`, and `requests` handle environment access, asynchronous execution, unique ID generation, and external API calls, respectively. `psycopg2` provides database connectivity to PostgreSQL, while `pydantic` offers structured data validation and modeling.\n",
    "\n",
    "The Semantic Kernel libraries enable creation of intelligent agents (`ChatCompletionAgent`), define plugins and function tools (`kernel_function`), manage prompt settings, and handle retrieval-augmented memory through `PostgresMemoryStore` and `SemanticTextMemory`. Finally, Azure OpenAI integration components (`AzureChatCompletion`, `AzureTextEmbedding`) allow the agent to generate responses and embeddings using cloud-based AI models.\n",
    "\n",
    "##### ⚙️ *Code Review Tasks*\n",
    "\n",
    "1. Run the cell below using the \"▶\" icon next to the cell.\n",
    "\n",
    "1. This will run the code and show the output below.  Since these are just imports, there is nothing to show at the end other than a check mark showing success.\n",
    "\n",
    "    > **Note:** The first time this code block is ran, it may take around 20-30 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "import psycopg2\n",
    "import uuid\n",
    "import requests\n",
    "from typing import Annotated\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatPromptExecutionSettings\n",
    "from semantic_kernel.functions import kernel_function, KernelArguments\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.memory.postgres import PostgresMemoryStore\n",
    "from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory\n",
    "from semantic_kernel.connectors.ai.open_ai.services.azure_text_embedding import AzureTextEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0194337c",
   "metadata": {},
   "source": [
    "### Part 3.3: Setup environmental connection variables\n",
    "\n",
    "##### 🧠 *Technical Notes*\n",
    "\n",
    "In order for our agent to interact with both Azure OpenAI services and the PostgreSQL database, we need to configure a few environment-specific connection variables. Rather than manually retrieving these values from the Azure Portal, we provide a shortcut: simply run the script located at `./Scripts/get_env.ps1` to automatically extract the correct credentials. After running the script, copy the output values into the fields below.\n",
    "\n",
    "This setup allows the agent to securely authenticate API requests to Azure OpenAI (using `AZURE_OPENAI_*` variables) and connect to the database where our case law data is stored (using the `DB_CONFIG` dictionary).\n",
    "\n",
    "##### ⚙️ *Code Review Tasks*\n",
    "\n",
    "1. Within VS Code, open a new terminal, and at the following path, enter:\n",
    "\n",
    "    `PS C:\\Users\\LabUser\\Downloads\\pg-sk-agents-lab> .\\Scripts\\get_env.ps1`\n",
    "\n",
    "1. From the output of the script in the terminal, copy the values for the following each into the variables in the code block below:\n",
    "    - `AZURE_OPENAI_ENDPOINT`\n",
    "    - `AZURE_OPENAI_KEY`\n",
    "    - `DB_CONFIG - HOST`\n",
    "    - `DB_CONFIG - PASSWORD`\n",
    "\n",
    "    > **Note:** For `DB_CONFIG - PASSWORD`, this is a very long string due to being an Entra ID Access Token, be sure to copy the entire string as the password.\n",
    "\n",
    "1. For the value for `{USER}`, this will be your Lab Username Credential, you can get these from the Lab Manual, in Part 3.3\n",
    "\n",
    "1. Once you have each of these fields filled in, then run the cell below using the \"▶\" icon next to the cell.  This will run the code and show the output below.  You will reuse these variables and objects throughout the lab notebook below.\n",
    "\n",
    "1. You should see a check mark when it completes, showing success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56021df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_ENDPOINT   = \"{AZURE_OPENAI_ENDPOINT}\"\n",
    "AZURE_OPENAI_KEY        = \"{AZURE_OPENAI_KEY}\"\n",
    "AZURE_OPENAI_DEPLOYMENT = \"gpt-4o\"\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"host\":     \"{HOST}\",\n",
    "    \"dbname\":   \"cases\",\n",
    "    \"user\":     \"{USER}\",\n",
    "    \"password\": \"{PASSWORD}\",\n",
    "    \"port\":     5432,\n",
    "    \"sslmode\":  \"require\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4a3fd1",
   "metadata": {},
   "source": [
    "### Part 3.4: Create Semantic Kernel Plugin for Basic Database Queries\n",
    "\n",
    "##### 🧠 *Technical Notes*\n",
    "\n",
    "In this step, we create a custom plugin called DatabaseSearchPlugin to give our agent the ability to interact directly with the case law database using basic SQL queries. This plugin uses the psycopg2 library to establish a connection to PostgreSQL, execute queries, and return results. We define two simple but important functions: `count_cases()` to return the total number of cases in the database, and `search_cases(keyword)` to perform a keyword search against case opinions. Each function is decorated with `@kernel_function`, which registers it as a callable tool within the Semantic Kernel framework. This makes these database operations available to the agent automatically during conversation, enabling the agent to retrieve real-time, grounded information from our dataset.\n",
    "\n",
    "##### ⚙️ *Code Review Tasks*\n",
    "\n",
    "1. Review the code below, notice the print statements outputting to the terminal the name of the function when it is called.  This will be helpful later when we run the agent, and we want to see what functions it chose to call.\n",
    "\n",
    "1. Run the cell below using the \"▶\" icon next to the cell.\n",
    "\n",
    "1. This will run the code and show the output below.  Since these are just imports, there is nothing to show at the end other than a check mark showing success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "284bbcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabaseSearchPlugin:\n",
    "        def __init__(self, cfg):\n",
    "            self.cfg = cfg\n",
    "\n",
    "        @kernel_function(description=\"Return the total number of cases in the database.\")\n",
    "        def count_cases(self) -> str:\n",
    "            \n",
    "            # print statement so we can see when this function chosen by the agent and is called\n",
    "            print(\"count_cases was called\")\n",
    "            \n",
    "            conn = psycopg2.connect(**self.cfg)\n",
    "            cur = conn.cursor()\n",
    "            cur.execute(\"SELECT COUNT(*) FROM cases;\")\n",
    "            n = cur.fetchone()[0]\n",
    "            conn.close()\n",
    "            return str(n)\n",
    "\n",
    "        @kernel_function(description=\"Find up to 10 case IDs and names whose opinion contains the given keyword.\")\n",
    "        def search_cases(self, keyword: str) -> str:\n",
    "            \n",
    "            # print statement so we can see when this function chosen by the agent and is called\n",
    "            print(\"search_cases was called\")\n",
    "            \n",
    "            conn = psycopg2.connect(**self.cfg)\n",
    "            cur = conn.cursor()\n",
    "            cur.execute(\n",
    "                \"SELECT id, name, opinion FROM cases WHERE opinion ILIKE %s LIMIT 10;\",\n",
    "                (f\"%{keyword}%\",)\n",
    "            )\n",
    "            rows = cur.fetchall()\n",
    "            conn.close()\n",
    "            if not rows:\n",
    "                return \"No matches\"\n",
    "            return \"\\n\".join(f\"{r[0]}: {r[1]}: {r[2][:1000]}\" for r in rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0006bb",
   "metadata": {},
   "source": [
    "### Part 3.5: Test Run of our New Agent\n",
    "\n",
    "##### 🧠 *Technical Notes*\n",
    "\n",
    "Now that we have created our first plugin, we're ready to assemble and test an initial version of our agent. In this step, we create a default `OpenAIChatPromptExecutionSettings` to define basic settings. We then create an instance of `AzureChatCompletion`, which serves as the underlying communication layer between our agent and Azure OpenAI. Using these components, we instantiate a `ChatCompletionAgent`, providing it a name, a set of behavioral instructions, and a list of available plugins (in this case, just `DatabaseSearchPlugin`).\n",
    "\n",
    "Finally, we send a sample user query to the agent and retrieve its response. This test validates that our agent can successfully invoke plugin functions, query the database, and integrate the results into a natural language reply.\n",
    "\n",
    "##### ⚙️ *Code Review Tasks*\n",
    "\n",
    "1. Review the code below, notice the following:\n",
    "    - Inside `ChatCompletionAgent` we define `instructions` which act as notion of a \"system prompt\" for the Agent to define its purpose and goals\n",
    "    - For now we are passing in our `DatabaseSearchPlugin` class, we will be creating more PlugIns to enhance the functionality of our agent in the next steps\n",
    "    - Notice the `user_query` variable, and how it is asking how many cases there are, plus about water leaking cases.\n",
    "\n",
    "1. Run the cell below using the \"▶\" icon next to the cell.  This invokes the agent and subsequent LLM calls, this may take a few moments to run.\n",
    "\n",
    "1. After the code runs, notice the following:\n",
    "    - There should have been 2 functions called: `count_cases` and `search_cases`\n",
    "    - This happened because the agent interpreted the prompt and made a decision to call these 2 functions\n",
    "    - Notice how we got back a clear response of 377 cases are in our database.  This was based on our `count_cases` database function giving the LLM grounded truth about our dataset.\n",
    "    - Lastly, notice how we asked for 10 cases, but only got 2.  This is because our `search_cases` function is just the ILIKE operator and not yet using a vector search.  It could only find 2 cases that matching using the basic keyword ILIKE search.  In our next lab sections, we will see how we can improve on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = OpenAIChatPromptExecutionSettings()\n",
    "    \n",
    "chat_svc = AzureChatCompletion(\n",
    "    deployment_name=AZURE_OPENAI_DEPLOYMENT,\n",
    "    endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_KEY)\n",
    "\n",
    "# Create agent with plugin and settings\n",
    "agent = ChatCompletionAgent(\n",
    "    service=chat_svc,\n",
    "    name=\"SK-Assistant\",\n",
    "    instructions=\"You are a helpful legal assistant.  Respond to the user with the name of the cases and reasoning why the cases are the most relevant, and a short sentence summary of the opinion of the cases.\",\n",
    "    plugins=[DatabaseSearchPlugin(DB_CONFIG)],\n",
    "    arguments=KernelArguments(settings)\n",
    ")\n",
    "\n",
    "user_query = \"How many cases are there, and find me 10 cases regarding the notion of water leaking.\"\n",
    "\n",
    "print(\"// Functions the Agent Called: //\")\n",
    "\n",
    "response = await agent.get_response(messages=user_query)\n",
    "\n",
    "print(\"// Agent Response: //\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1206c174",
   "metadata": {},
   "source": [
    "### Part 3.6: Improve Agent Accuracy by Adding Semantic Re-ranking Query Plugin\n",
    "\n",
    "##### 🧠 *Technical Notes*\n",
    "\n",
    "In this step, we add a new plugin called `SemanticRerankingPlugin` to increase the precision of our agent’s search results. Instead of relying only on keyword matching, this plugin uses semantic search and re-ranking to evaluate results based on the meaning and intent of the user query.\n",
    "\n",
    "It works in two phases: first, it performs a vector similarity search using Azure OpenAI embeddings to find approximately relevant cases; then, it reorders these using a separate model (e.g., `semantic_relevance`) that scores and ranks the results for deeper semantic alignment. This two-step approach helps the agent prioritize results that are not just textually similar, but also topically and contextually relevant—making it ideal for legal queries where nuance matters. As with other tools, this function is registered using `@kernel_function`, so the agent can intelligently decide when to use it.\n",
    "\n",
    "##### ⚙️ *Code Review Tasks*\n",
    "\n",
    "1. Before running this code block, we need to run a SQL script on the database.\n",
    "    - In VS Code, in the folder structure, in the folder `./Scripts/` navigate to the `setup_reranker.sql` file\n",
    "    - Once inside the file, still in VS Code, press on the keyboard `CTRL+SHIFT+P` to open the VS Code action panel, type `PGSQL Connect` and select the top `PGSQL: Connect` option\n",
    "    - Once prompted, select the Connection you made in the earlier steps in the lab\n",
    "    - You will then be asked the port number for the Connection, just hit `enter` to accept the default\n",
    "    - You should now be Connected to your database in the `setup_reranker.sql` file\n",
    "    - Next we need to replace the `{ENDPOINT}` and `{KEY}` tokens with the real values.  You can get these in the Skillable Lab Manual, on Part 3.6\n",
    "    - In the editor window, click the \">\" button in the top right to run the script\n",
    "    - This will setup our connection to Azure ML via our `azure_ai` PostgreSQL database extension, and create 2 PostgresSQL PL/SQL functions needed for semantic re-ranking\n",
    "\n",
    "1. Review the code:\n",
    "    - Notice the following enhancements:\n",
    "        - This plugin introduces a function called `search_semantic_reranked_cases`, designed to deliver higher-quality search results by understanding the semantic meaning of the query rather than relying on basic keyword matches.\n",
    "        - The function is decorated with `@kernel_function`, which makes it available to the agent as a callable tool-this is how Semantic Kernel enables function calling automatically based on user intent.\n",
    "\n",
    "    - Check out the SQL logic inside the code, notice how it includes two key phases:\n",
    "        - (Phase 1) A vector similarity search using OpenAI-generated embeddings to find top 60 candidate cases.\n",
    "        - (Phase 2) A semantic re-ranking step that uses an external re-ranker model (semantic_relevance) to evaluate and reorder those 60 based on relevance scores.\n",
    "        - This hybrid approach helps ensure that even when the user’s phrasing doesn’t exactly match the database text, relevant results can still be surfaced based on meaning and context.\n",
    "\n",
    "    - Observe how this plugin builds on the earlier keyword search:\n",
    "        - The previous `search_cases()` method used `ILIKE` for fuzzy keyword matching. That works for exact or near-exact phrases but misses nuance.\n",
    "        - This plugin improves accuracy and recall, especially for complex queries or abstract legal concepts where keyword overlap may be weak.\n",
    "        - This function will be automatically called by the agent if the prompt includes phrases like \"high accuracy is important\" or contains complex, open-ended search intent.\n",
    "        - For example, a prompt like: \"*Help me find the most relevant cases about tenant water damage, with high accuracy*\" will likely trigger this plugin over the basic one.\n",
    "\n",
    "1. Finally, run the code block cell by clicking the \"▶\" button on the left side of the code block.\n",
    "    - This will run the code but there will be no output yet.\n",
    "    - Since this is just a class definition, there is nothing to show at the end other than a check mark showing success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef674482",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticRerankingPlugin:\n",
    "        def __init__(self, cfg):\n",
    "            # Store the database configuration for later use\n",
    "            self.cfg = cfg\n",
    "\n",
    "        @kernel_function(description=\"Use semantic re-ranking function to query and find cases matching the query based on semantic intent and relevance.  Use this function when high accuracy is needed.\")\n",
    "        def search_semantic_reranked_cases(self, query: str) -> str:\n",
    "            \n",
    "            # Log when the function is invoked\n",
    "            print(\"search_semantic_reranked_cases was called\")\n",
    "            \n",
    "            # Connect to the PostgreSQL database\n",
    "            conn = psycopg2.connect(**self.cfg)\n",
    "            cur = conn.cursor()\n",
    "\n",
    "            # Execute a SQL query that performs semantic vector search and re-ranking\n",
    "            cur.execute(\n",
    "                \"\"\"\n",
    "                -- // Step 1: Create an embedding from the user's query using Azure OpenAI //\n",
    "                WITH embedding_query AS (\n",
    "                    SELECT azure_openai.create_embeddings('text-embedding-3-small', %s)::vector AS embedding\n",
    "                ),\n",
    "\n",
    "                -- // Step 2: Find top 60 cases whose vector is closest to the query embedding (initial vector search) //\n",
    "                vector AS (\n",
    "                    SELECT cases.id as case_id, cases.name AS case_name, cases.opinion, RANK() OVER (ORDER BY opinions_vector <=> embedding) AS vector_rank\n",
    "                    FROM cases, embedding_query\n",
    "                    ORDER BY opinions_vector <=> embedding\n",
    "                    LIMIT 60\n",
    "                ),\n",
    "\n",
    "                -- // Step 3: Call a semantic re-ranking function to evaluate the 60 candidates and assign relevance scores //\n",
    "                semantic AS (\n",
    "                    SELECT * \n",
    "                    FROM jsonb_array_elements(\n",
    "                            semantic_relevance(%s, 60)\n",
    "                        ) WITH ORDINALITY AS elem(relevance)\n",
    "                ),\n",
    "\n",
    "                -- // Step 4: Join the initial vector results with semantic scores and rank by highest relevance //\n",
    "                semantic_ranked AS (\n",
    "                    SELECT semantic.relevance::DOUBLE PRECISION AS relevance, RANK() OVER (ORDER BY relevance DESC) AS semantic_rank,\n",
    "                            semantic.*, vector.*\n",
    "                    FROM vector\n",
    "                    JOIN semantic ON vector.vector_rank = semantic.ordinality\n",
    "                    ORDER BY semantic.relevance DESC\n",
    "                )\n",
    "\n",
    "                -- // Step 5: Return the top 10 results after semantic re-ranking //\n",
    "                SELECT case_id, case_name, opinion\n",
    "                FROM semantic_ranked\n",
    "                LIMIT 10;\n",
    "                \"\"\", (query, query)) # Pass the query twice: once for embedding, once for semantic re-ranker\n",
    "\n",
    "            rows = cur.fetchall() # Fetch the final ranked results\n",
    "\n",
    "            conn.close() # Always close the connection after use\n",
    "\n",
    "            # Return a nicely formatted list of top results or fallback message if no matches\n",
    "            if not rows:\n",
    "                return \"No matches\"\n",
    "            return \"\\n\".join(f\"{r[0]}: {r[1]}: {r[2][:1000]}\" for r in rows) # Truncate long opinions to 1000 chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace1491f",
   "metadata": {},
   "source": [
    "### Part 3.7: Add a GraphRAG Query PlugIn to the Agent for Additional Accuracy Improvements\n",
    "\n",
    "##### 🧠 *Technical Notes*\n",
    "\n",
    "In this step, we build another advanced plugin, `GraphDatabasePlugin`, that combines vector search with graph analysis to find the most influential cases related to a query topic. The `search_graph_cases` method first uses an embedding-based similarity search to semantically rank cases from the cases table. This ensures that only cases meaningfully related to the query are considered further.\n",
    "\n",
    "After narrowing the results semantically, the query leverages **Apache AGE** - a PostgreSQL extension that enables property graph querying via Cypher syntax. Specifically, it matches citations (relationships between cases) in the `case_graph` graph. By counting the number of incoming edges (citations) for each case, we can rank cases based on their influence or importance within the graph. Cases with more citations are prioritized, resulting in a more nuanced retrieval that considers both semantic relevance and citation authority.\n",
    "\n",
    "This hybrid retrieval technique is an example of **GraphRAG (Graph Retrieval-Augmented Generation)** and represents a more sophisticated form of grounded information retrieval for legal, academic, or research applications.\n",
    "\n",
    "##### ⚙️ *Code Review Tasks*\n",
    "\n",
    "1. Before running this code block, we need to run a SQL script on the database.\n",
    "    - In VS Code, in the folder structure, in the folder `./Scripts/` navigate to the `create_graph.sql` file\n",
    "    - Once inside the file, still in VS Code, press on the keyboard `CTRL+SHIFT+P` to open the VS Code action panel, type `PGSQL Connect` and select the top `PGSQL: Connect` option\n",
    "    - Once prompted, select the Connection you made in the earlier steps in the lab\n",
    "    - You will then be asked the port number for the Connection, just hit `enter` to accept the default\n",
    "    - You should now be Connected to your database in the `create_graph.sql` file\n",
    "    - In the editor window, click the \">\" button in the top right to run the script\n",
    "    - This will build our graph database via the Apache AGE extension in our Azure PostgreSQL database using our loaded 377 legal cases\n",
    "\n",
    "1. Next, because we are using the Apache AGE PostgreSQL Extension to provide us Graph database capabilities, we need to enable the Extension on our database.\n",
    "    - Run the following PowerShell script within VS Code\n",
    "    - Within VS Code, open a new terminal, and at the following path, enter:\n",
    "\n",
    "        `PS C:\\Users\\LabUser\\Downloads\\pg-sk-agents-lab> .\\Scripts\\load_age.ps1`\n",
    "\n",
    "        > **Note:** This will run through 3 main commands, all together will take around 60-120 seconds.\n",
    "\n",
    "1. Review the code:\n",
    "    - This plugin allows the agent to find legal cases that are not only semantically similar to a user's query but also highly cited by other cases - providing both relevance and legal importance. The `@kernel_function` decorator makes this method callable by the agent.\n",
    "    - Look at the `semantic_ranked` CTE (Common Table Expression). This ranks cases by their similarity to the input query using embedding-based vector comparison (<=>). The function limits results to the top 60 most semantically similar opinions using Azure OpenAI’s embedding model.\n",
    "    - Examine the graph CTE. It runs a Cypher query on the `case_graph` to count how many times each case is cited by others. These citation counts are joined to the semantic results using the case ID. This allows the plugin to prioritize not just relevant cases, but those that are also influential in the citation network.\n",
    "    - The final `SELECT` returns 10 cases with the highest number of citations among the semantically relevant ones. The list is ordered by refs `DESC`, meaning more citations come first. Each opinion is truncated to the first 1000 characters to keep responses concise.\n",
    "\n",
    "1. Finally, run the code block cell by clicking the \"▶\" button on the left side of the code block.\n",
    "    - This will run the code but there will be no output yet.\n",
    "    - Since this is again just a class definition, there is nothing to show at the end other than a check mark showing success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ec57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDatabasePlugin:\n",
    "        def __init__(self, cfg):\n",
    "            # Store the database configuration dictionary\n",
    "            self.cfg = cfg\n",
    "\n",
    "        @kernel_function(description=\"Use an advanced accuracy query to find important cases with high levels of citations about the query topic.\")\n",
    "        def search_graph_cases(self, query: str) -> str:\n",
    "            \n",
    "            # Debug log to indicate function was triggered\n",
    "            print(\"search_graph_cases was called\")\n",
    "            \n",
    "            # Connect to the PostgreSQL database using the provided config\n",
    "            conn = psycopg2.connect(**self.cfg)\n",
    "            cur = conn.cursor()\n",
    "\n",
    "            # Execute a compound query using semantic search + graph analysis (Apache AGE)\n",
    "            cur.execute(\n",
    "                \"\"\"\n",
    "                -- // Step 1: Set the schema search path to include Apache AGE graph catalog //\n",
    "                SET search_path = public, ag_catalog, \"$user\";\n",
    "\n",
    "                -- // Step 2: Rank cases semantically using embedding similarity //\n",
    "                WITH semantic_ranked AS (\n",
    "                    SELECT id, name, opinion, opinions_vector\n",
    "                    FROM cases\n",
    "                    ORDER BY opinions_vector <=> azure_openai.create_embeddings('text-embedding-3-small', %s)::vector\n",
    "                    LIMIT 60\n",
    "                ),\n",
    "                -- // Step 3: Use a Cypher graph query to count how many citations (edges) each case has //\n",
    "                graph AS (\n",
    "                    SELECT graph_query.refs, semantic_ranked.*, graph_query.case_id \n",
    "                    FROM semantic_ranked\n",
    "                    LEFT JOIN cypher('case_graph', $$\n",
    "                        MATCH ()-[r]->(n)\n",
    "                        RETURN n.case_id, COUNT(r) AS refs\n",
    "                    $$) as graph_query(case_id TEXT, refs BIGINT)\n",
    "                    ON semantic_ranked.id = graph_query.case_id::int\n",
    "                )\n",
    "                -- // Step 4: Return the top 10 cases, prioritized by number of citations (refs) //\n",
    "                SELECT id, name, opinion\n",
    "                FROM graph\n",
    "                ORDER BY refs DESC NULLS LAST\n",
    "                LIMIT 10;\n",
    "                \"\"\", \n",
    "                (f\"%{query}%\",)\n",
    "            )\n",
    "            rows = cur.fetchall() # Fetch all resulting rows\n",
    "            conn.close() # Close the database connection\n",
    "\n",
    "            # Return either \"No matches\" or a formatted list of results\n",
    "            if not rows:\n",
    "                return \"No matches\"\n",
    "            return \"\\n\".join(f\"{r[0]}: {r[1]}: {r[2][:1000]}\" for r in rows) # Truncate long opinions to 1000 chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3164fd",
   "metadata": {},
   "source": [
    "### Part 3.8: Re-Assemble our Agent with new advanced PlugIns and Re-Test\n",
    "\n",
    "##### 🧠 *Technical Notes*\n",
    "\n",
    "In this step, we re-assemble the full agent by attaching all of the custom plugins we’ve created so far: `DatabaseSearchPlugin`, `SemanticRerankingPlugin`, and `GraphDatabasePlugin`. These plugins give the agent access to different querying strategies, from simple keyword searches to advanced semantic filtering and graph-based citation analysis. By registering all plugins in the plugins list, we enable the agent to choose the right tool based on the intent expressed in the user’s prompt.\n",
    "\n",
    "##### ⚙️ *Code Review Tasks*\n",
    "\n",
    "1. Review the code below, notice the following:\n",
    "    - We only need to re-define our agent object using the `ChatCompletionAgent` class\n",
    "    - Notice we are now adding our new PlugIns on the line:\n",
    "        - `plugins=[DatabaseSearchPlugin(DB_CONFIG),SemanticRerankingPlugin(DB_CONFIG),GraphDatabasePlugin(DB_CONFIG)],`    \n",
    "    - Notice the `user_query` variables, there are some additional ones you can try testing yourself by uncommenting one at a time, then re-running the code cell\n",
    "\n",
    "1. Run the cell below using the \">\" icon next to the cell.  This invokes the agent and subsequent LLM calls, this may take a few moments to run.\n",
    "\n",
    "1. After the code runs, notice the following:\n",
    "    - Depending on the prompt you chosen, there should have been between 2-3 functions called, such as: `search_graph_cases` and `search_semantic_reranked_cases`\n",
    "    - Notice how we asked for 10 cases, and now got 10 cases. This is because the we are now using semantic vector search, not just keyword search for the database queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51df009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-Create agent with new plugins\n",
    "agent = ChatCompletionAgent(\n",
    "    service=chat_svc,\n",
    "    name=\"SK-Assistant\",\n",
    "    instructions=\"You are a helpful legal assistant.  Respond to the user with the name of the cases and reasoning why the cases are the most relevant, and a short sentence summary of the opinion of the cases.\",\n",
    "    plugins=[DatabaseSearchPlugin(DB_CONFIG),SemanticRerankingPlugin(DB_CONFIG),GraphDatabasePlugin(DB_CONFIG)],\n",
    "    arguments=KernelArguments(settings)\n",
    ")\n",
    "\n",
    "# Try these different prompts to see how the agent responds:\n",
    "# Remove one comment at a time to test different prompts\n",
    "user_query = \"Help me find 10 highly relevant cases related to water leaking in my personal home apartment from the floor above.  High accuracy is important, and high number of citations is important.  Also how many cases are there overall?\"\n",
    "#user_query = \"Bring into 1 list of 10 cases, ranked by relevancy -- Help me find 10 highly relevant cases related to water leaking in my personal home apartment from the floor above.  High accuracy is important, and high number of citations is important.\"\n",
    "#user_query = \"How many cases are there, and high accuracy is important, help me find 10 highly relevant cases related to water leaking in my apartment.\"\n",
    "\n",
    "print(\"// Functions the Agent Called: //\")\n",
    "\n",
    "response = await agent.get_response(messages=user_query)\n",
    "\n",
    "print(\"// Agent Response: //\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed32517a",
   "metadata": {},
   "source": [
    "### Part 3.9: Adding a Weather PlugIn to the Agent\n",
    "\n",
    "##### 🧠 *Technical Notes*\n",
    "\n",
    "To enhance our legal assistant with real-world context, we introduce a `WeatherPlugin` that enables the agent to retrieve historical weather data (specifically rainfall) based on a given date and geographic location. This is especially useful in real estate or tenant-landlord disputes where weather-related damage (e.g., leaks or flooding) may be a legal factor. The plugin uses the Open-Meteo Archive API, a free and reliable weather data service.\n",
    "\n",
    "When a user prompt mentions a need for weather data—such as \"What was the rainfall on Feb 1, 2024, in Seattle?\"—the agent will automatically call this function. The returned data provides accurate, grounded evidence that enhances the agent’s response and credibility.\n",
    "\n",
    "##### ⚙️ *Code Review Tasks*\n",
    "\n",
    "1. Review the code below and observe the following:\n",
    "    - The `@kernel_function` decorator registers this function so the agent can call it based on user intent.\n",
    "    - The plugin uses `requests.get()` to make a live API call to Open-Meteo, passing latitude, longitude, and date parameters.\n",
    "    - The response is parsed from JSON and extracts the precipitation value from the `daily.precipitation_sum` array.\n",
    "    - The result is returned as a readable string with the date, coordinates, and rainfall in millimeters.\n",
    "\n",
    "1. Run the cell below using the \"▶\" (Run) button. There is no visible output until the function is called by the agent in a relevant prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9190f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherPlugin:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Get total precipitation (in mm) on a given date and location (latitude, longitude).\"\n",
    "    )\n",
    "    def get_historical_rainfall(self, date: str, latitude: float, longitude: float) -> str:\n",
    "        \"\"\"\n",
    "        date: YYYY-MM-DD\n",
    "        latitude, longitude: WGS84 coords\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"get_historical_rainfall was called\")\n",
    "\n",
    "        url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "        params = {\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude,\n",
    "            \"start_date\": date,\n",
    "            \"end_date\":   date,\n",
    "            \"daily\":      \"precipitation_sum\",\n",
    "            \"timezone\":   \"UTC\"\n",
    "        }\n",
    "        resp = requests.get(url, params=params)\n",
    "        resp.raise_for_status()\n",
    "\n",
    "        data = resp.json()\n",
    "        # the API returns a list for daily.precipitation_sum\n",
    "        rain_mm = data[\"daily\"][\"precipitation_sum\"][0]\n",
    "        return f\"On {date} at ({latitude}, {longitude}), total precipitation was {rain_mm} mm.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3613a5df",
   "metadata": {},
   "source": [
    "### Part 3.10: Add our new Weather PlugIn to our Agent and Re-Test\n",
    "\n",
    "##### 🧠 *Technical Notes*\n",
    "\n",
    "In this step, we complete our agent by including the new `WeatherPlugin` alongside our database and semantic plugins. This enables the agent to answer more complex, multi-part prompts that require both legal case analysis and external factual grounding—such as historical rainfall on a specific date and location.\n",
    "\n",
    "When a user prompt mentions weather-related conditions (e.g., \"*What was the rainfall on February 1, 2024, in Seattle?*\"), the agent can automatically call the appropriate plugin function. Semantic Kernel handles function selection based on the natural language intent, so all tools are available simultaneously without manual switching. This demonstrates the power of multi-plugin orchestration in agent design—allowing a single agent to reason across legal data and real-world APIs in one coherent response.\n",
    "\n",
    "##### ⚙️ *Code Review Tasks*\n",
    "\n",
    "1. Review how the `WeatherPlugin()` is added to the list of available plugins in the `ChatCompletionAgent`.\n",
    "\n",
    "1. Examine the user_query. Note how it includes both:\n",
    "    - A factual request (weather evidence),\n",
    "    - And a legal research task (finding relevant legal cases).\n",
    "\n",
    "1. Run the cell below using the \"▶\" (Run) button and observe:\n",
    "    - Which functions the agent chooses to call (check your logs or printed output),\n",
    "    - How the agent combines different results into a single response.\n",
    "    - Try editing the user_query to include other dates or cities and observe how the weather data changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b672c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-Create agent with new plugins\n",
    "agent = ChatCompletionAgent(\n",
    "    service=chat_svc,\n",
    "    name=\"SK-Assistant\",\n",
    "    instructions=\"You are a helpful legal assistant.  Respond to the user with the name of the cases and reasoning why the cases are the most relevant, and a short sentence summary of the opinion of the cases.\",\n",
    "    plugins=[DatabaseSearchPlugin(DB_CONFIG),SemanticRerankingPlugin(DB_CONFIG),GraphDatabasePlugin(DB_CONFIG),WeatherPlugin()],\n",
    "    arguments=KernelArguments(settings)\n",
    ")\n",
    "\n",
    "# Try these different prompts to see how the agent responds:\n",
    "# Remove one comment at a time to test different prompts\n",
    "user_query = \"What was the rainfall on 2024-02-01 in Seattle, WA? I need this for evidence.  Also High accuracy is important, help me find 10 highly relevant cases related to water leaking in my clients apartment.\"\n",
    "#user_query = \"I am a real estate lawyer, so cases need to be related to real estate law.\"\n",
    "#user_query = \"Find me 10 cases regarding the notion of water leaking.\"\n",
    "#user_query = \"How many cases are there, and high accuracy is important, help me find 10 highly relevant cases related to water leaking in my apartment.\"\n",
    "#user_query = \"Help me find 10 highly relevant cases related to water leaking in my personal home apartment from the floor above.  High accuracy is important, and high number of citations is important.  Also how many cases are there overall?\"\n",
    "#user_query = \"Bring into 1 list of 10 cases, ranked by relevancy -- Help me find 10 highly relevant cases related to water leaking in my personal home apartment from the floor above.  High accuracy is important, and high number of citations is important.\"\n",
    "#user_query = \"How many cases are in my database? What was the rainfall on 2024-02-01 in Seattle, WA? I need this for evidence.  Also High accuracy is important, help me find 10 highly relevant cases related to water leaking in my clients apartment.\"\n",
    "\n",
    "print(\"// Functions the Agent Called: //\")\n",
    "response = await agent.get_response(messages=user_query)\n",
    "\n",
    "print(\"// Agent Response: //\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8784b47b",
   "metadata": {},
   "source": [
    "### Part 3.11: Adding Memory into the Agent\n",
    "\n",
    "##### 🧠 *Technical Notes*\n",
    "\n",
    "In this final step, we complete our agent’s capabilities by enabling semantic memory using SemanticTextMemory backed by a PostgreSQL vector store. This allows the agent to store and recall relevant prior user queries and its own responses—creating a more personalized and context-aware experience over time.\n",
    "\n",
    "When a new prompt is received, the agent retrieves semantically similar past queries from memory using embedding-based vector search. These memories are then prepended to the current prompt, giving the agent important context and continuity across interactions. This memory is especially useful in real-world legal scenarios where a user may build a case over several prompts, and the agent must retain prior details to offer more precise, relevant guidance.\n",
    "\n",
    "##### ⚙️ *Code Review Tasks*\n",
    "\n",
    "1. Review how PostgresMemoryStore and AzureTextEmbedding are used to set up vector-based memory for the agent.\n",
    "\n",
    "1. Examine how the user query is stored into memory, and how top related queries are retrieved with semantic search.\n",
    "\n",
    "1. Observe how the memory context is prepended to the new prompt before being passed to the agent.\n",
    "\n",
    "1. Run the cell below using the \"▶\" (Run) button and inspect:\n",
    "    - How the agent’s output incorporates the memory context,\n",
    "    - What gets saved to memory as both the query and the agent’s reply,\n",
    "    - How this memory layer enables continuity in multi-turn conversations.\n",
    "\n",
    "1. Test running through the first 3 sample prompts below, by uncommenting a single prompt, one at a time\n",
    "    - As you run through these, this helps to showcase the memory functionality as the Agent keeps track of these facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f914df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try running the following 3 prompts, one at a time, this helps to showcase the memory functionality as the Agent keeps track of these facts\n",
    "#user_query = \"I am a real estate lawyer\"\n",
    "#user_query = \"My client has lived in their apartment for 10 years\"\n",
    "#user_query = \"How many cases are there, and high accuracy is important, help me find 10 highly relevant cases related to water leaking in my apartment.\"\n",
    "\n",
    "# Additional test cases to see how the agent responds:\n",
    "#user_query = \"Find me some cases regarding the notion of my house falling down.\"\n",
    "#user_query = \"Find me 10 cases regarding the notion of water leaking.\"\n",
    "#user_query = \"Help me find 10 highly relevant cases related to water leaking in my personal home apartment from the floor above.  High accuracy is important, and high number of citations is important.  Also how many cases are there overall?\"\n",
    "#user_query = \"Bring into 1 list of 10 cases, ranked by relevancy -- Help me find 10 highly relevant cases related to water leaking in my personal home apartment from the floor above.  High accuracy is important, and high number of citations is important.\"\n",
    "\n",
    "# Construct the PostgreSQL connection string for use with memory storage\n",
    "conn_str = (\n",
    "f\"host={DB_CONFIG['host']} \"\n",
    "f\"port={DB_CONFIG['port']} \"\n",
    "f\"dbname={DB_CONFIG['dbname']} \"\n",
    "f\"user={DB_CONFIG['user']} \"\n",
    "f\"password={DB_CONFIG['password']} \"\n",
    "f\"sslmode={DB_CONFIG['sslmode']}\"\n",
    ")\n",
    "\n",
    "# Initialize a Postgres-backed memory store for saving and retrieving vector-based memories\n",
    "memory_store = PostgresMemoryStore(\n",
    "    connection_string=conn_str,\n",
    "    default_dimensionality=1536\n",
    ")\n",
    "\n",
    "# Set up the Azure OpenAI embedding service to convert text into vector embeddings\n",
    "embedding_generator = AzureTextEmbedding(\n",
    "    deployment_name=\"text-embedding-3-small\",\n",
    "    endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_KEY\n",
    ")\n",
    "\n",
    "# Combine storage and embedding logic into a semantic memory system\n",
    "semantic_memory = SemanticTextMemory(\n",
    "    storage=memory_store,\n",
    "    embeddings_generator=embedding_generator\n",
    ")\n",
    "\n",
    "# Save the user query into memory\n",
    "await semantic_memory.save_information(\n",
    "    collection=\"agent_memories\",    # Memory collection name\n",
    "    text=user_query,                # Text content to embed and store\n",
    "    id=str(uuid.uuid4()),           # Unique ID for this memory entry        \n",
    "    description=\"User query\"        # Optional label or tag for this entry\n",
    ")\n",
    "\n",
    "# Search memory for the top-3 most semantically similar past queries\n",
    "recalls = await semantic_memory.search(\n",
    "    collection=\"agent_memories\",\n",
    "    query=user_query,\n",
    "    limit=3\n",
    ")\n",
    "\n",
    "# Format the recalled memories as bullet points for context injection\n",
    "memory_context = \"\\n\".join(f\"- {m.text}\" for m in recalls)\n",
    "\n",
    "# Construct a new prompt that includes relevant memory context followed by the current query\n",
    "prompt = (\n",
    "    f\"Here are things we’ve discussed before:\\n{memory_context}\\n\\n\"\n",
    "    f\"{user_query}\"\n",
    ")\n",
    "\n",
    "print(\"// Functions the Agent Called: //\")\n",
    "response = await agent.get_response(messages=prompt)\n",
    "\n",
    "print(\"// Prompt with Added Memory Context: //\")\n",
    "print(prompt)\n",
    "\n",
    "print(\"// Agent Response: //\")\n",
    "print(response.content)\n",
    "\n",
    "# Save the agent's reply to memory as well, completing a full query-response memory cycle\n",
    "await semantic_memory.save_information(\n",
    "    collection=\"agent_memories\",\n",
    "    text=str(response.content),\n",
    "    id=str(uuid.uuid4()),\n",
    "    description=\"Agent reply\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610d1a23",
   "metadata": {},
   "source": [
    "## Congratulations you have completed the Lab!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
